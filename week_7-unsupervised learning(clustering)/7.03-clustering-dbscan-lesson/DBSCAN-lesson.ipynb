{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Clustering:  DBSCAN\n",
    "_**D**ensity-**B**ased **S**patial **C**lustering of **A**pplications with **N**oise_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![](https://i.stack.imgur.com/5aikc.png)\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- What is DBSCAN?\n",
    "- How does DBSCAN work?\n",
    "- How does DBSCAN compare to K-Means and Hierarchical Clustering?\n",
    "- Implementation\n",
    "- Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (~2 mins) What is clustering?\n",
    "\n",
    "> Clustering is an unsupervised learning technique we employ to group “similar” data points together -- ok but elaborate please!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN: Density-based Spatial Clustering of Applications with Noise\n",
    "- Clusters of high density are separated by clusters of low density\n",
    "\n",
    "DBSCAN is a widely used and applicable clustering algorithm - given that it takes minimum predefined input and can discover clusters of any shape, not just the gausian-like clusters that K-Means tends to converge on. This way, we can discover difficult to distinguish patterns and glean more useful insights.\n",
    "\n",
    "> No single clustering algorithm is the best for all the purposes. This means, that there are situations where DBSCAN does a good job at finding clusters, while sometimes it's very bad.  This is all dependant on our data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN is a density based clustering algorithm, meaning that the algorithm finds clusters by seeking areas of the dataset that have a higher density of points than the rest of the dataset.\n",
    "\n",
    "![](https://i.imgflip.com/1nylt0.jpg)\n",
    "\n",
    "_Unlike other clustering methods, DBSCAN may not assign points to any cluster at all if the conditions we paramatize DBSCAN on don't match the characteristics of our data!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How DBSCAN Works\n",
    "\n",
    "## $\\epsilon$: epsilon & minimum number of points\n",
    "\n",
    "When we use **DBSCAN**, it requires two input parameters - **epsilon**: $\\epsilon$, which defines a distance boundary from a point, and the **minimum number of points** within $\\epsilon$ necessary to form a cluster, which we'll call the minimum points.\n",
    "\n",
    "\n",
    "![](https://snag.gy/0lWkw3.jpg?updated=now)\n",
    "\n",
    "> - <span style=\"color: gray;\">Gray</span> - $\\epsilon$ distance boundary\n",
    "> - <span style=\"color: red;\">Red</span> - $\\epsilon$ distance\n",
    "> - <span style=\"color: blue;\">Blue</span> - Minimum points within $\\epsilon$\n",
    "> - Black - Core sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose an “epsilon” and “min_samples”\n",
    "1. Pick an arbitrary point (_core sample_), and check if there are at least “min_samples” points within distance “epsilon”\n",
    " - If **yes**, add those points to the cluster and check each of the new points\n",
    " - If **no**, choose another arbitrary point (_core sample_) to start a new cluster\n",
    "1. Stop once all points have been checked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (~30 mins) Group Activity\n",
    "\n",
    "> **Larger classes**\n",
    "> - Split up into groups of 4-5\n",
    "> \n",
    "> **Smaller classes**\n",
    "> - Work in groups of pairs\n",
    ">\n",
    "\n",
    "Split up into groups, then use the whiteboard to explore the concept of DBSCAN visually through a set of points.  \n",
    "\n",
    "- Visually explain how the DBSCAN algorithm works, step by step.\n",
    "- Present explanation to your local class.\n",
    "- Spend **~15 mins working** and **~15 mins presenting** to your local class.  If we need more time, we will adjust accordingly.\n",
    "\n",
    "**Bonus:**\n",
    "- Take a snapshot of your work and post it in the specified thread\n",
    "- Describe cases where this works well and when it doesn't\n",
    "- Compare with K-Means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN Explained\n",
    "\n",
    "DBSCAN will take the epsilon and minimum points we provided it and cluster all of the points in a neighborhood, first passing the minimum points requirement and then clustering each of the points within epsilon distance to form the clusters. Once one cluster is formed, the algorithm then moves to a new datapoint, and seeks to find related points to form yet another cluster; this will continue until DBSCAN simply runs out of points!\n",
    "\n",
    "![](https://snag.gy/i38qNp.jpg)\n",
    ">_This example is missing points but perhaps draw some underneath the projection to illustrate the example._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm visualization:\n",
    "\n",
    "http://www.naftaliharris.com/blog/visualizing-dbscan-clustering/ \n",
    "\n",
    "Let’s play with this a bit.\n",
    "\n",
    "### Independently, select the “Pimpled Smiley” distribution of points. What is an optimal epsilon? What about minimum number of points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN vs K-Means\n",
    "\n",
    "- **K-Means** can be thought of as a \"general\" clustering approach, DBSCAN performs especially well with unevenly distributed, non-gausian clusters.\n",
    "\n",
    "- The fundamental difference with DBSCAN lies in the fact that it is density based rather than **K-Means**, which calculates clusters based on distance from a central point / geometric mean of points.\n",
    "\n",
    "- **DBSCAN** can be useful to us when we have a lot of dense data. If we used **K-Means** on this data, the algorithm would effectively give us just one large cluster! However with DBSCAN, we can actually break down this cluster into smaller groups to see their attributes.\n",
    "\n",
    "![](https://snag.gy/73NXe5.jpg)\n",
    "\n",
    "**What are the advantages over K-Means?**\n",
    "\n",
    "## DBSCAN vs Hierarchical (briefly)\n",
    "\n",
    "> Even though we haven't explicitly used hierachical clustering, we should at least review a few rules of thumb, briefly.\n",
    "\n",
    "- When choosing epsilon in the minimum points in DBSCAN, a selection of < 2 will result in a linkage cluster - essentially the same result as if you were to perform a **hierarchical clustering**. To diversify the DBSCAN, we therefore must give it a significant amount of points to form a cluster.\n",
    "\n",
    "- **DBSCAN** is density based, which means that it determines clusters based on the number of points in a specific area, whereas in heirarchical clustering, we only care about the minmum distances of single points between clusters to merge on.\n",
    "\n",
    "**What are the advantages over hierarchical methods?**\n",
    "\n",
    "> _As a general rule when choosing the minimum points - you should always aim to have the minimum number of points be greater or equal to the amount of dimensions in your data, plus one. This typically will give the algorithm a good estimation of how to evaluate the clusters. Calculating epsilon is a bit trickier and uses a method called the k-distance, which can help visualize the best epsilon._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple sklearn Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import load_iris\n",
    "from plot_code import plot_dbscan\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "dbscan        =  DBSCAN(eps=0.3, min_samples=10, ).fit(X[:, [0, 3]])\n",
    "core_samples  =  dbscan.core_sample_indices_\n",
    "labels        =  dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DBSCAN algorithm in Python returns two items - the **core samples** and the **labels**. The **core samples** are the points which the algorithm initially finds and searches around the neighborhood to form the cluster, and the **labels** are simply the cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine data / plot data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- DBSCAN will cluster on density based assumptions.\n",
    "- **Epsilon** and **min_samples**.\n",
    "- Not every sample is guaranteed to end up in a cluster.\n",
    "- Compared to K-Means, DBSCAN is better at finding irregularly formed clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Practice\n",
    "\n",
    "To get a real sense of how DBSCAN works, while not required, try the guided exercize of coding DBSCAN from scratch using the notebook [DBSCAN-by-hand.ipynb](DBSCAN-by-hand.ipynb) (also check out the solution code).\n",
    "\n",
    "![](https://snag.gy/UAB6Pk.jpg)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
