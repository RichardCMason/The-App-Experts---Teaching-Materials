{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Object-Oriented Programming: Coding a Normal Distribution Class\n",
    "\n",
    "_Author: Justin Pounders (ATL)_\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following modules are used for plotting and generating data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These imports are needed by the class\n",
    "import numpy as np\n",
    "from scipy.special import erf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Mission\n",
    "### Should you choose to accept it...\n",
    "\n",
    "Let's define normal.  Specifically, let's create a class that represents various facets of the normal distribution.  First, some review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Shape of Normal\n",
    "\n",
    "Mathematically, the probability density function (pdf) for the normal (or Gaussian) distribution can be written as follows:\n",
    "\n",
    "$$\n",
    "f(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}.\n",
    "$$\n",
    "\n",
    "The cumulative distribution function (cdf), on the other hand, is\n",
    "\n",
    "$$\n",
    "F( x | \\mu, \\sigma^2) = \\frac{1}{2} \\left[ 1 + \\text{erf}\\left(\\frac{x-\\mu}{\\sigma\\sqrt{2}}\\right) \\right]\n",
    "$$\n",
    "\n",
    "where $\\text{erf}(\\cdot)$ is the \"error function.\"  This error function is technically called a \"special function\" (yes, really), and for today's purposes we will calculate its value using the `erf` function imported from `scipy.stats` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time for `class`\n",
    "\n",
    "Let's lay out some requirements for our \"normal class\":\n",
    "\n",
    "- Let's name the class `Gaussian`\n",
    "- The class attributes should include\n",
    "\n",
    "  - `mu`, the mean\n",
    "  - `sigma`, the standard deviation\n",
    "  - `is_fit`, boolean indicating if mean/standard deviation were given or calculated.  More on this later.\n",
    "  \n",
    "- The class methods will include\n",
    "\n",
    "  - `pdf`\n",
    "  - `cdf`\n",
    "  - `plot`\n",
    "  - `fit`\n",
    "  - `likelihood`\n",
    "  \n",
    "To keep things bite-sized and digestible, let's build the class up in 3 stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1\n",
    "\n",
    "First define you class and create the `__init__` \"constructor\" method.  This is also a good place to set class attributes.\n",
    "\n",
    "Next, continue by implementing `pdf`, `cdf` and `plot`.\n",
    "\n",
    "- The `pdf` method should take a single value `x` as input and return the normal PDF corresponding to `x`.\n",
    "- The `cdf` method should take a single value `x` as input and return the normal CDF corresponding to `x`.\n",
    "- The `plot` method should make a plot of the distribution and return the corresponding `matplotlib` figure.  (Bonus: add an input flag to plot either the PDF _or_ the CDF.)\n",
    "\n",
    "> The above bullets are not a complete specification.  Feel free to rif and define the class that makes the most sense to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2\n",
    "\n",
    "Copy your class down below, and let's continue to add some functionality.\n",
    "\n",
    "Specifically let's implement a `fit` method.  You can \"fit\" a normal distribution to a set of data by calculating the mean and standard deviation of the data, then assigning these values to a normal distribution.\n",
    "\n",
    "For our class, try passing the `fit` method the raw data and have everything else happen inside the method.\n",
    "\n",
    "I'll provide some test data to get started.  Once you think you've implemented it correctly you could test it out using something like the following, which will plot a histogram on top of you normal.\n",
    "\n",
    "```python\n",
    "norm = Gaussian()              # This will call the __init__ you implemented\n",
    "norm.fit(df.samples.values)    # This is the fit method you just implemented.\n",
    "fig = norm.plot(df.samples.min(), df.samples.max())   # This is the plot method you implemented\n",
    "\n",
    "# And here is we plot the histogram\n",
    "df.hist(ax=fig.get_axes(), normed=True, bins=20)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the sample data\n",
    "mu = 105\n",
    "sigma = 20\n",
    "test_norm = stats.norm(mu, sigma)\n",
    "\n",
    "np.random.seed(seed=42)\n",
    "samples = test_norm.rvs(1000)\n",
    "df = pd.DataFrame({'samples':samples})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3 (Bonus Level!)\n",
    "\n",
    "Now let's add a `likelihood` method.  In probability, the likelihood function tells us how likely it is that our data came from a given distribution.\n",
    "\n",
    "For example, let's say that we have some normal distribution with fixed mean and standard deviation: $f(x | \\mu, \\sigma^2)$.\n",
    "\n",
    "Now let's say we have a set of data, $x_1, x_2, x_3, ... x_N$ that we _think_ are sampled from our normal distribution.\n",
    "\n",
    "The likelihood function tells how well our data fits the distribution; it is calculated as\n",
    "\n",
    "$$\n",
    "\\text{likelihood} = \\prod_{i=1}^N f(x_i | \\mu, \\sigma^2)\n",
    "$$\n",
    "\n",
    "*These numbers can get really small!*  It is therefore very common to calculate the \"log likelihood:\"\n",
    "\n",
    "$$\n",
    "\\text{log(likelihood)} = \\sum_{i=1}^N \\ln\\left[f(x_i | \\mu, \\sigma^2)\\right]\n",
    "$$\n",
    "\n",
    "If you use the sample data from \"Stage 2\" then the following code should give you about an answer of about -4393.167.\n",
    "\n",
    "```python\n",
    "norm = Gaussian()\n",
    "norm.fit(df.samples.values)\n",
    "norm.log_likelihood(df.samples.values)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, check out [Chapter 4](http://anandology.com/python-practice-book/object_oriented_programming.html) in the _Python Practice Book_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
