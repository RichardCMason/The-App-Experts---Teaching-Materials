{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of web scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "\n",
    "![What is HTML?](http://designshack.designshack.netdna-cdn.com/wp-content/uploads/htmlbasics-0.jpg)\n",
    "\n",
    "One of the largest sources of data in the world is all around us — the web. Most people consume the web in some form every day. One of the most powerful Python tool sets we'll learn allows us to extract and normalize data from unstructured sources such as web pages.  \n",
    "\n",
    "**If you can see it, it can be scraped, mined, and put into a DataFrame.**\n",
    "\n",
    "Before we begin the actual process of web scraping with Python, it's important to cover the basic constructs that describe HTML as unstructured data. \n",
    "\n",
    "We'll then cover a powerful selection technique called XPath and look at a basic workflow using a framework called [Scrapy](http://www.scrapy.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='html'></a>\n",
    "\n",
    "## Hypertext Markup Language (HTML)\n",
    "\n",
    "---\n",
    "\n",
    "In the HTML document object model (DOM), everything is a node:\n",
    " * The document itself is a document node.\n",
    " * All HTML elements are element nodes.\n",
    " * All HTML attributes are attribute nodes.\n",
    " * Text inside HTML elements are text nodes.\n",
    " * Comments are comment nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='elements'></a>\n",
    "### Elements\n",
    "Elements begin and end with opening and closing \"tags,\" which are defined by namespaced, encapsulated strings. These namespaces, which begin and end the elements, must be the same. \n",
    "\n",
    "```html\n",
    "<title>I am a title.</title>\n",
    "<p>I am a paragraph.</p>\n",
    "<strong>I am bold.</strong>\n",
    "```\n",
    "\n",
    "When you have several different titles or paragraphs on a single page, you can assign ID values to namespaces to make more unique reference points. IDs are also useful for labelling nested elements.\n",
    "```html\n",
    "<title id ='title_1'>I am the first title.</title>\n",
    "<p id ='para_1'>I am the first paragraph.</p>\n",
    "<title id ='title_2'>I am the second title.</title>\n",
    "<p id ='para_2'>I am the second paragraph.</p>\n",
    "```\n",
    "\n",
    "\n",
    "**Elements can have parents and children.**\n",
    "It's important to remember that an element can be both a parent and a child — whether an element is referred to as a parent or child depends on the specific element you're referencing.\n",
    "\n",
    "\n",
    "```html\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the child of 'parent.'\n",
    "        <div id = 'child_2'>I am the child of 'child_1.'\n",
    "            <div id = 'child_3'>I am the child of 'child_2.'\n",
    "                <div id = 'child_4'>I am the child of 'child_4.'</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```\n",
    "**or**\n",
    "```html\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the parent of 'child_2.'\n",
    "        <div id = 'child_2'>I am the parent of 'child_3.'\n",
    "            <div id = 'child_3'> I am the parent of 'child_4.'\n",
    "                <div id = 'child_4'>I am not a parent. </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attributes'></a>\n",
    "### Attributes\n",
    "\n",
    "HTML elements can also have attributes. They describe the properties and characteristics of elements. Some affect how the element behaves or looks in terms of the output rendered by the browser.\n",
    "\n",
    "The most common element is an anchor element. Anchor elements often have an \"href\" element, which tells the browser where to go after it's clicked. An anchor element is typically formatted in bold type and is sometimes underlined as a visual cue to differentiate it.\n",
    "\n",
    "**The markup that describes an element with attributes literally looks like this:**\n",
    "\n",
    "```html\n",
    "<a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">An Awesome Website</a>\n",
    "```\n",
    "\n",
    "**However, this element, once rendered, looks like this:**\n",
    "\n",
    "[An Awesome Website](https://www.youtube.com/watch?v=dQw4w9WgXcQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='element-hierarchy'></a>\n",
    "### Element Hierarchy\n",
    "\n",
    "![Nodes](http://www.computerhope.com/jargon/d/dom1.jpg)\n",
    "\n",
    "**Literally represented as:**\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    \n",
    "    <head>\n",
    "        <title>Example</title>\n",
    "    </head>\n",
    "    \n",
    "    <body>\n",
    "        <h1>Example Page</h1>\n",
    "        <p>This is an example page.</p>\n",
    "    </body>\n",
    "    \n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='html-resources'></a>\n",
    "### Additional HTML Resources\n",
    "\n",
    "Read all about the different elements supported by modern browsers:\n",
    " * [HTML5 cheat sheet](http://websitesetup.org/html5-cheat-sheet/).\n",
    " * [Mozilla HTML element reference](https://developer.mozilla.org/en-US/docs/Web/HTML/Element).\n",
    " * [HTML5 visual cheat sheet](http://www.unitedleather.biz/PDF/HTML5-Visual-Cheat-Sheet1.pdf).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practical'></a>\n",
    "\n",
    "## Using Requests and Beautiful Soup to Extract Information From a Web Page\n",
    "\n",
    "---\n",
    "\n",
    "Beautiful Soup is a Python library that's useful for pulling data out of HTML and XML files. It works with many parsers, such as XPath, and can be executed in an IDE, meaning it can be easier to work with when first extracting information from HTML.\n",
    "\n",
    "Please make sure that the required packages are installed: \n",
    "\n",
    "```bash\n",
    "# Beautiful Soup:\n",
    "> conda install beautifulsoup4\n",
    "> conda install lxml\n",
    "\n",
    "# Or if conda doesn't work:\n",
    "> pip install beautifulsoup4\n",
    "> pip install lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open(\"sample.html\"), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Hello, World!</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>Header 1</h1>\n",
       "<h2>Header 2</h2>\n",
       "<p>This is a paragraph</p>\n",
       "<a href=\"https://www.google.com/\">Google it!</a>\n",
       "<h3>What's in a div?</h3>\n",
       "<div class=\"divvy-it-up\" id=\"foobar\">\n",
       "<p id=\"layer1\">I'm in a div.  Yeah!</p>\n",
       "<div>\n",
       "<p id=\"layer2\">I'm in a div, too!</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"todo\">\n",
       "<ul>\n",
       "<li> Take out trash</li>\n",
       "<li> Walk dog</li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"something\">\n",
       "<ol>\n",
       "<li>One</li>\n",
       "<li>Two</li>\n",
       "</ol>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Hello, World!</title>\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n"
     ]
    }
   ],
   "source": [
    "olist = soup.find('ol')\n",
    "for list_item in olist.find_all('li'):\n",
    "    print(list_item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"layer2\">I'm in a div, too!</p>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_results = soup.body.find_all('div', {'class':'divvy-it-up'})\n",
    "div_results[0].find_all('p', {'id':'layer2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's buy a car!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](assets/craigslist.jpg)\n",
    "\n",
    "https://atlanta.craigslist.org/atl/wan/d/cheap-or-free-running-car-or/6485015376.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "### 1) Fetch the content by URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code:  200\n",
      "\n",
      "First part of HTML document fetched as string:\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html class=\"no-js\">\n",
      "<head>\n",
      "<title>Cheap or free running car or truck - wanted - by owner - sale</title>\n",
      "    \t<link rel=\"canonical\" href=\"https://atlanta.craigslist.org/atl/wan/d/cheap-or-free-running-car-or/6485015376.html\">\n",
      "\t<meta name=\"description\" content=\"Hi, I am looking for someone who would like to sell or give away a free car or truck. I have a vehicle its been down for sometimes now and will cost to much to fix. I do not have the extra income to...\">\n",
      "\t<meta name=\"robots\" content=\"noarchive,nofollow,unavailable_after: 29-Mar-18 20:26:39 EDT\">\n",
      "\t<meta name=\"twitter:card\" content=\"preview\">\n",
      "\t<meta property=\"og:description\" content=\"Hi, I am looking for someone who would\n"
     ]
    }
   ],
   "source": [
    "# You'll need the requests library in order to fully utilize bs4.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Target web page:\n",
    "url = \"https://atlanta.craigslist.org/atl/wan/d/cheap-or-free-running-car-or/6485015376.html\"\n",
    "\n",
    "# Establishing the connection to the web page:\n",
    "response = requests.get(url)\n",
    "\n",
    "# You can use status codes to understand how the target server responds to your request.\n",
    "# Ex., 200 = OK, 400 = Bad Request, 403 = Forbidden, 404 = Not Found.\n",
    "print('Status Code: ',response.status_code)\n",
    "\n",
    "# Pull the HTML string out of requests and convert it to a Python string.\n",
    "html = response.text\n",
    "\n",
    "# The first 700 characters of the content.\n",
    "print(\"\\nFirst part of HTML document fetched as string:\\n\")\n",
    "print(html[:700])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on [request status codes](http://www.restapitutorial.com/httpstatuscodes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "### 2) Parse the HTML document with Beautiful Soup.\n",
    "\n",
    "This step allows us to access the elements of the document by XPath expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Cheap or free running car or truck - wanted - by owner - sale</title>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Singular element:\n",
    "soup.html.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cheap or free running car or truck - wanted - by owner - sale\n"
     ]
    }
   ],
   "source": [
    "# Just the text between elements:\n",
    "print(soup.html.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"header-logo\" href=\"/\" name=\"logoLink\">CL</a>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find single or multiple elements.\n",
    "# First parameter:\n",
    "element = soup.find_all(\"a\", {\"class\": \"header-logo\"})\n",
    "element[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$200'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_search = soup.findAll('span', {\"class\": \"price\"})\n",
    "price_search[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What about all car listings in ATL:\n",
    "response = requests.get(\"https://atlanta.craigslist.org/search/cto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "result_list = soup.find_all('p', {'class':'result-info'})\n",
    "\n",
    "results = []\n",
    "for result in result_list:\n",
    "    car = {}\n",
    "    car['text'] = result.find('a', {'class':'hdrlnk'}).text\n",
    "    car['price'] = int(result.find('span', {'class':'result-price'}).text.replace('$',''))\n",
    "    hood = result.find('span', {'class':'result-hood'})\n",
    "    car['hood'] = hood.text.replace('(','').replace(')','') if hood else None\n",
    "    results.append(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hood</th>\n",
       "      <th>price</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snellville</td>\n",
       "      <td>4180</td>\n",
       "      <td>2004 Lexus ES 330 great Condition runs and dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adairsville</td>\n",
       "      <td>3500</td>\n",
       "      <td>1997 Honda crv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lawrenceville</td>\n",
       "      <td>800</td>\n",
       "      <td>1999 Nissan Quest - parts or mechanic's special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atl</td>\n",
       "      <td>2000</td>\n",
       "      <td>2002 Ford Explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atl</td>\n",
       "      <td>2500</td>\n",
       "      <td>1999 Lexus es300 one owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Atl</td>\n",
       "      <td>2500</td>\n",
       "      <td>1998 Honda CR-V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Newnan</td>\n",
       "      <td>8500</td>\n",
       "      <td>2013 Nissan Leaf SV - CPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Atl</td>\n",
       "      <td>1700</td>\n",
       "      <td>2000 jeep Cherokee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>7999</td>\n",
       "      <td>2009 BMW 328i $7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>snellville</td>\n",
       "      <td>8900</td>\n",
       "      <td>Toyota Tundra 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kennesaw</td>\n",
       "      <td>18500</td>\n",
       "      <td>2015 Jeep Cherokee Latitude 4x4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Decatur</td>\n",
       "      <td>2500</td>\n",
       "      <td>2005 BUICK CENTURY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Norcross</td>\n",
       "      <td>12</td>\n",
       "      <td>Good Condition Grand cherokee - $1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>6998</td>\n",
       "      <td>**2009 Mazda 6 ** Touring **</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>6900</td>\n",
       "      <td>2010 Nissan Rogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>2998</td>\n",
       "      <td>2005 Dodge Grand Caravan SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>6998</td>\n",
       "      <td>2009 Mazda 6 ** Touring **</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td>10698</td>\n",
       "      <td>**2014 HONDA CIVIC ** BACKUP CAMERA**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>9800</td>\n",
       "      <td>2014 HONDA CIVIC LX \"BACKUP CAMERA\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>2500</td>\n",
       "      <td>Nice Ford Focus Low Miles $2500 Firm!! Gas Saver!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>None</td>\n",
       "      <td>2100</td>\n",
       "      <td>2007 Mitsubishi Eclipse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>111 Prospect St,</td>\n",
       "      <td>1585</td>\n",
       "      <td>Japanese Built! Honda Civic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lilburn</td>\n",
       "      <td>4900</td>\n",
       "      <td>Dependable Ford Freestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Norcross/Buford</td>\n",
       "      <td>2600</td>\n",
       "      <td>2002 Ford Crown Victoria Lx Sport*CLEAN TITLE*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lilburn</td>\n",
       "      <td>4900</td>\n",
       "      <td>2006 Ford Freestyle (3rd Row)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Norcross</td>\n",
       "      <td>2600</td>\n",
       "      <td>2002 Ford Crown Victoria Lx Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lilburn</td>\n",
       "      <td>4900</td>\n",
       "      <td>Dependable 2006 Ford Freestyle with 3rd row</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Florence</td>\n",
       "      <td>10000</td>\n",
       "      <td>2012 Dodge Charger on 26\"Dubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cumming</td>\n",
       "      <td>11950</td>\n",
       "      <td>F250 6.0 Turbo Diesel Powerstroke 2005 Excelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dalton ga</td>\n",
       "      <td>5000</td>\n",
       "      <td>2003 Toyota Corolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Dawsonville</td>\n",
       "      <td>4200</td>\n",
       "      <td>2008 VW Jetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>None</td>\n",
       "      <td>600</td>\n",
       "      <td>Mint condition BMW M3 OEM hood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Peachtree Corners</td>\n",
       "      <td>13950</td>\n",
       "      <td>Honda CRV-EX - Super Low Miles, One Owner, Exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Cumming</td>\n",
       "      <td>13000</td>\n",
       "      <td>Jeep Wrangler Sahara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>None</td>\n",
       "      <td>38000</td>\n",
       "      <td>1949 Chevy 5 window</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mabelton</td>\n",
       "      <td>4395</td>\n",
       "      <td>Nissan Altima 2009 *MUST SEE*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Gwinnett</td>\n",
       "      <td>5500</td>\n",
       "      <td>2004 Chevy express van 15 passenger v8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>None</td>\n",
       "      <td>49999</td>\n",
       "      <td>2017 Ford F-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Buford</td>\n",
       "      <td>5500</td>\n",
       "      <td>2004 Ford Ranger XLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ozark</td>\n",
       "      <td>1</td>\n",
       "      <td>mercedes 450sl 1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>None</td>\n",
       "      <td>28900</td>\n",
       "      <td>2012 Ford F550 Flatbed crew cab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Grayson</td>\n",
       "      <td>4500</td>\n",
       "      <td>2007 Honda Odyssey LX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>None</td>\n",
       "      <td>7499</td>\n",
       "      <td>2014 Kia Soul base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ozark</td>\n",
       "      <td>2000</td>\n",
       "      <td>porsche 924s(project)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Dawsonville</td>\n",
       "      <td>6000</td>\n",
       "      <td>2006 GMC Envoy DENALI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Lula ga</td>\n",
       "      <td>3500</td>\n",
       "      <td>1990 mustang gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>BROOKHEAVEN</td>\n",
       "      <td>4900</td>\n",
       "      <td>2006 2nd OWNER ACURA TL 6cyl No Accident Like New</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Stone mountain</td>\n",
       "      <td>6500</td>\n",
       "      <td>2012 Nissan Altima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>3500</td>\n",
       "      <td>2006 First Owner Mazda3 Excellent Condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Buford ga</td>\n",
       "      <td>4000</td>\n",
       "      <td>2007 Hyundai Santa Fe 3 Row seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>braselton ga</td>\n",
       "      <td>300</td>\n",
       "      <td>1978 DODGE PICKUP TRUCK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Douglasville</td>\n",
       "      <td>11000</td>\n",
       "      <td>2000 Dodge Ram 2500 diesel 5.9 4x4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Peachtree City</td>\n",
       "      <td>3199</td>\n",
       "      <td>Suzuki Grand Vitara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Paulding county</td>\n",
       "      <td>3200</td>\n",
       "      <td>2009 Chrysler Sebring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NM</td>\n",
       "      <td>1200000</td>\n",
       "      <td>HONEY WAGON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Lafayette</td>\n",
       "      <td>7500</td>\n",
       "      <td>05 Toyota Tundra 4 door Access Cab *New Tires*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Powder springs</td>\n",
       "      <td>2400</td>\n",
       "      <td>2004 Gold Kia Optima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>15000</td>\n",
       "      <td>Honda Civic 2014 LX for Sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Marietta</td>\n",
       "      <td>44000</td>\n",
       "      <td>2016 Mercedes-Benz G-Class G 63 AMG Non-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Tampa</td>\n",
       "      <td>1111111</td>\n",
       "      <td>1941 willys coupe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   hood    price  \\\n",
       "0            Snellville     4180   \n",
       "1           Adairsville     3500   \n",
       "2         Lawrenceville      800   \n",
       "3                   Atl     2000   \n",
       "4                   Atl     2500   \n",
       "5                   Atl     2500   \n",
       "6                Newnan     8500   \n",
       "7                   Atl     1700   \n",
       "8                  None     7999   \n",
       "9            snellville     8900   \n",
       "10             Kennesaw    18500   \n",
       "11              Decatur     2500   \n",
       "12             Norcross       12   \n",
       "13                 None     6998   \n",
       "14                 None     6900   \n",
       "15                 None     2998   \n",
       "16                 None     6998   \n",
       "17                 None    10698   \n",
       "18                 None     9800   \n",
       "19                 None     2500   \n",
       "20                 None     2100   \n",
       "21     111 Prospect St,     1585   \n",
       "22              Lilburn     4900   \n",
       "23      Norcross/Buford     2600   \n",
       "24              Lilburn     4900   \n",
       "25             Norcross     2600   \n",
       "26              Lilburn     4900   \n",
       "27             Florence    10000   \n",
       "28              Cumming    11950   \n",
       "29            Dalton ga     5000   \n",
       "..                  ...      ...   \n",
       "90          Dawsonville     4200   \n",
       "91                 None      600   \n",
       "92    Peachtree Corners    13950   \n",
       "93              Cumming    13000   \n",
       "94                 None    38000   \n",
       "95             Mabelton     4395   \n",
       "96             Gwinnett     5500   \n",
       "97                 None    49999   \n",
       "98               Buford     5500   \n",
       "99                ozark        1   \n",
       "100                None    28900   \n",
       "101             Grayson     4500   \n",
       "102                None     7499   \n",
       "103               ozark     2000   \n",
       "104         Dawsonville     6000   \n",
       "105             Lula ga     3500   \n",
       "106         BROOKHEAVEN     4900   \n",
       "107      Stone mountain     6500   \n",
       "108             Atlanta     3500   \n",
       "109           Buford ga     4000   \n",
       "110        braselton ga      300   \n",
       "111        Douglasville    11000   \n",
       "112      Peachtree City     3199   \n",
       "113     Paulding county     3200   \n",
       "114                  NM  1200000   \n",
       "115           Lafayette     7500   \n",
       "116      Powder springs     2400   \n",
       "117             Atlanta    15000   \n",
       "118            Marietta    44000   \n",
       "119               Tampa  1111111   \n",
       "\n",
       "                                                  text  \n",
       "0    2004 Lexus ES 330 great Condition runs and dri...  \n",
       "1                                       1997 Honda crv  \n",
       "2      1999 Nissan Quest - parts or mechanic's special  \n",
       "3                                   2002 Ford Explorer  \n",
       "4                           1999 Lexus es300 one owner  \n",
       "5                                      1998 Honda CR-V  \n",
       "6                            2013 Nissan Leaf SV - CPO  \n",
       "7                                   2000 jeep Cherokee  \n",
       "8                                  2009 BMW 328i $7999  \n",
       "9                                   Toyota Tundra 2008  \n",
       "10                     2015 Jeep Cherokee Latitude 4x4  \n",
       "11                                  2005 BUICK CENTURY  \n",
       "12               Good Condition Grand cherokee - $1900  \n",
       "13                        **2009 Mazda 6 ** Touring **  \n",
       "14                                   2010 Nissan Rogue  \n",
       "15                         2005 Dodge Grand Caravan SE  \n",
       "16                          2009 Mazda 6 ** Touring **  \n",
       "17               **2014 HONDA CIVIC ** BACKUP CAMERA**  \n",
       "18                 2014 HONDA CIVIC LX \"BACKUP CAMERA\"  \n",
       "19   Nice Ford Focus Low Miles $2500 Firm!! Gas Saver!  \n",
       "20                             2007 Mitsubishi Eclipse  \n",
       "21                         Japanese Built! Honda Civic  \n",
       "22                           Dependable Ford Freestyle  \n",
       "23      2002 Ford Crown Victoria Lx Sport*CLEAN TITLE*  \n",
       "24                       2006 Ford Freestyle (3rd Row)  \n",
       "25                   2002 Ford Crown Victoria Lx Sport  \n",
       "26         Dependable 2006 Ford Freestyle with 3rd row  \n",
       "27                       2012 Dodge Charger on 26\"Dubs  \n",
       "28   F250 6.0 Turbo Diesel Powerstroke 2005 Excelle...  \n",
       "29                                 2003 Toyota Corolla  \n",
       "..                                                 ...  \n",
       "90                                       2008 VW Jetta  \n",
       "91                      Mint condition BMW M3 OEM hood  \n",
       "92   Honda CRV-EX - Super Low Miles, One Owner, Exc...  \n",
       "93                                Jeep Wrangler Sahara  \n",
       "94                                 1949 Chevy 5 window  \n",
       "95                       Nissan Altima 2009 *MUST SEE*  \n",
       "96              2004 Chevy express van 15 passenger v8  \n",
       "97                                     2017 Ford F-150  \n",
       "98                                2004 Ford Ranger XLT  \n",
       "99                                 mercedes 450sl 1980  \n",
       "100                    2012 Ford F550 Flatbed crew cab  \n",
       "101                              2007 Honda Odyssey LX  \n",
       "102                                 2014 Kia Soul base  \n",
       "103                              porsche 924s(project)  \n",
       "104                              2006 GMC Envoy DENALI  \n",
       "105                                    1990 mustang gt  \n",
       "106  2006 2nd OWNER ACURA TL 6cyl No Accident Like New  \n",
       "107                                 2012 Nissan Altima  \n",
       "108        2006 First Owner Mazda3 Excellent Condition  \n",
       "109                   2007 Hyundai Santa Fe 3 Row seat  \n",
       "110                            1978 DODGE PICKUP TRUCK  \n",
       "111                 2000 Dodge Ram 2500 diesel 5.9 4x4  \n",
       "112                                Suzuki Grand Vitara  \n",
       "113                              2009 Chrysler Sebring  \n",
       "114                                        HONEY WAGON  \n",
       "115  05 Toyota Tundra 4 door Access Cab *New Tires*...  \n",
       "116                               2004 Gold Kia Optima  \n",
       "117                       Honda Civic 2014 LX for Sale  \n",
       "118     2016 Mercedes-Benz G-Class G 63 AMG Non-smoker  \n",
       "119                                  1941 willys coupe  \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice**\n",
    "\n",
    "- How would you get the next 120 results?\n",
    "- How would you get the text associated with a particular car?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You'll need the requests library in order to fully utilize bs4.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Target web page:\n",
    "url = \"https://www.datatau.com/\"\n",
    "\n",
    "# Establishing the connection to the web page:\n",
    "response = requests.get(url)\n",
    "\n",
    "# You can use status codes to understand how the target server responds to your request.\n",
    "# Ex., 200 = OK, 400 = Bad Request, 403 = Forbidden, 404 = Not Found.\n",
    "print(response.status_code)\n",
    "\n",
    "# Pull the HTML string out of requests and convert it to a Python string.\n",
    "html = response.text\n",
    "\n",
    "# The first 700 characters of the content.\n",
    "#print(html)\n",
    "\n",
    "More information on [request status codes](http://www.restapitutorial.com/httpstatuscodes.html).\n",
    "\n",
    "<a id='step2'></a>\n",
    "### 2) Parse the HTML document with Beautiful Soup.\n",
    "\n",
    "This step allows us to access the elements of the document by XPath expressions.\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# This code collects the titles, links and urls for DataTau's homepage\n",
    "\n",
    "# List to store results\n",
    "results_list = []\n",
    "\n",
    "# Get all the <td class=\"title\"... elements\n",
    "all_td = soup.find_all('td', {'class':'title'})\n",
    "for element in all_td:\n",
    "    # start a dictionary to store this item's data\n",
    "    result = {}\n",
    "    \n",
    "    # get the title and full link/url\n",
    "    a_href = element.find('a')\n",
    "    if a_href:\n",
    "        result['title'] = a_href.text   # element text\n",
    "        result['link'] = a_href['href'] # href link\n",
    "        \n",
    "    # get the url domain\n",
    "    span = element.find('span', {'class':'comhead'})\n",
    "    if span:\n",
    "        result['url'] = span.text.strip()[1:-1]\n",
    "        \n",
    "    # only store \"full\" rows of data\n",
    "    if len(result) == 3:\n",
    "        results_list.append(result)\n",
    "        \n",
    "results_list[0]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(results_list)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
