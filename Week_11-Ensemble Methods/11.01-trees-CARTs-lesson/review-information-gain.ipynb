{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review:  Information Gain\n",
    "\n",
    "\n",
    "\n",
    "**Information gain** is a way for us to figure out how much information is contained within the resulting X from $ P(y\\ |\\ X\\ =\\ condition) $.\n",
    "\n",
    "> - $H$ can be either $Gini$ or $Entropy$ function\n",
    "> - $N_j$ \\# of class observations\n",
    "> - $N$ total number of observations\n",
    "> - $child_j$ proportion of class observations given condition\n",
    "\n",
    "## $$ \\Delta = H(\\text{parent}) - \\sum_{\\text{children}}\\frac{N_j}{N}H(\\text{child}_j) $$\n",
    "\n",
    "$$IG(T,a) = H(T) - H(T|a)$$ \n",
    "\n",
    "IG closer to 1 is desirable, unlike Gini or Entropy on its own.  IG is the weighed sum of either Gini or Entropy of all conditions for a node.\n",
    "\n",
    "\n",
    "$H$ can be Gini or Entropy but we can use this to understand the overall information gain from parent to children.  If we wanted to see the first calculated gain for our first node, we could use the following example.\n",
    "\n",
    ">_This may look like a lot but we'll go into more detail in our next lesson to see how we can relate this idea of \"best decision\".  Simply stated, we can test multiple conditions for a parent node, then measure it's information gain.  We will select the condition with the best information gain for our split._\n",
    "\n",
    "<img src=\"https://snag.gy/DijRCf.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://snag.gy/brEiJ2.jpg\">\n",
    "\n",
    "- **Parent node** (all data in this case of the root node)\n",
    " - **5** total observations\n",
    " - **3/5** obsevations belong to class \"Bacon\"\n",
    " - **2/5** observations belong to class \"Vegetable\"\n",
    " - **parent gini** is:  $1 - ((3/5)^2\\ +\\ (2/5)^2) = .48$\n",
    " \n",
    " \n",
    " \n",
    "- **Child nodes** created as a result of color == \"pink\"<br><br>\n",
    "\n",
    "    - $Gini(\\text{Data where color}\\ ==\\ \"pink\")$\n",
    "      - **2** total records in partition\n",
    "      - **2/2** of obsevations belong to \"Bacon\" category\n",
    "      - Gini with a class balance of **2/2 is 0** _(That's pure!)_<br><br>\n",
    "      \n",
    "    - $Gini(\\text{Data where color}\\ !=\\ \"pink)$\n",
    "      - **3** total records in partition\n",
    "      - **2/3** of observations, $P(y = \"Vegetable\")$\n",
    "      - **1/3** of observations, $P(y = \"Bacon\")$\n",
    "      - Gini is: $1 - ((2/3)^2\\ +\\ (1/3)^2) = .44$\n",
    "\n",
    "> _Remember: A **gini** of .5 is maximum score for that metric.  For **entropy**, the maximum is 1._\n",
    "\n",
    "**Information gain** for condition when parent to child nodes when condition is \"color = pink\", is:\n",
    "\n",
    "## $.48 - (\\frac{2}{2} * 0 + \\frac{3}{5} * .44) = .216$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
