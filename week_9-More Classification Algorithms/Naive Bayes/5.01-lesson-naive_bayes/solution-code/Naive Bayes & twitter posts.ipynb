{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes\n",
    "\n",
    "We've looked at the Naive Bayes classifier from a probability point of view. Now let's apply code to it to a natural language processing problem.\n",
    "\n",
    "### Before we begin... what is natural language processing?\n",
    "\n",
    "- If I'm explaining this to my non-technical peers, natural language processing is just a way for us to get computers to understand written language the way you and I do.\n",
    "\n",
    "- If I'm explaining this to someone with a more technical background, natural language processing is a set of tools that represent words as numbers. This is commonly done by feature engineering (i.e. turning words into columns in your dataframe), but more complicated methods exist.\n",
    "\n",
    "You'll often see natural language processing abbreviated as **NLP**.\n",
    "\n",
    "We'll cover NLP in detail later. In this case, we've already done the NLP for you where we turn social media posts into features. You and I will use these features in a Naive Bayes classification model to predict whether a post comes from Twitter or Facebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../processed_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>trusted_judgments</th>\n",
       "      <th>audience_feature</th>\n",
       "      <th>bias_feature</th>\n",
       "      <th>message_feature</th>\n",
       "      <th>label_feature</th>\n",
       "      <th>source_feature</th>\n",
       "      <th>text_feature</th>\n",
       "      <th>00</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>û_</th>\n",
       "      <th>ûª</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªre</th>\n",
       "      <th>ûªs</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûò</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>766192484.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>national</td>\n",
       "      <td>partisan</td>\n",
       "      <td>policy</td>\n",
       "      <td>From: Trey Radel (Representative from Florida)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>766192485.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>national</td>\n",
       "      <td>partisan</td>\n",
       "      <td>attack</td>\n",
       "      <td>From: Mitch McConnell (Senator from Kentucky)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>VIDEO - #Obamacare:  Full of Higher Costs and ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>766192486.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>national</td>\n",
       "      <td>neutral</td>\n",
       "      <td>support</td>\n",
       "      <td>From: Kurt Schrader (Representative from Oregon)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>Please join me today in remembering our fallen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>766192487.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>national</td>\n",
       "      <td>neutral</td>\n",
       "      <td>policy</td>\n",
       "      <td>From: Michael Crapo (Senator from Idaho)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>RT @SenatorLeahy: 1st step toward Senate debat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>766192488.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>national</td>\n",
       "      <td>partisan</td>\n",
       "      <td>policy</td>\n",
       "      <td>From: Mark Udall (Senator from Colorado)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>.@amazon delivery #drones show need to update ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 509 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      unit_id  trusted_judgments audience_feature bias_feature  \\\n",
       "0           0  766192484.0                1.0         national     partisan   \n",
       "1           1  766192485.0                1.0         national     partisan   \n",
       "2           2  766192486.0                1.0         national      neutral   \n",
       "3           3  766192487.0                1.0         national      neutral   \n",
       "4           4  766192488.0                1.0         national     partisan   \n",
       "\n",
       "  message_feature                                     label_feature  \\\n",
       "0          policy    From: Trey Radel (Representative from Florida)   \n",
       "1          attack     From: Mitch McConnell (Senator from Kentucky)   \n",
       "2         support  From: Kurt Schrader (Representative from Oregon)   \n",
       "3          policy          From: Michael Crapo (Senator from Idaho)   \n",
       "4          policy          From: Mark Udall (Senator from Colorado)   \n",
       "\n",
       "  source_feature                                       text_feature   00 ...   \\\n",
       "0        twitter  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...  0.0 ...    \n",
       "1        twitter  VIDEO - #Obamacare:  Full of Higher Costs and ...  0.0 ...    \n",
       "2        twitter  Please join me today in remembering our fallen...  0.0 ...    \n",
       "3        twitter  RT @SenatorLeahy: 1st step toward Senate debat...  0.0 ...    \n",
       "4        twitter  .@amazon delivery #drones show need to update ...  0.0 ...    \n",
       "\n",
       "   young  youtube   û_   ûª  ûªm  ûªre  ûªs  ûªt  ûªve   ûò  \n",
       "0    0.0      0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  \n",
       "1    0.0      0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  \n",
       "2    0.0      0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  \n",
       "3    0.0      0.0  0.0  0.0  0.0   0.0  1.0  0.0   0.0  0.0  \n",
       "4    0.0      0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 509 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have social media data! This includes almost 5,000 messages on either Twitter or Facebook from various politicians. We can use the features we generated to predict things like whether the source is Twitter or Facebook, whether the bias is neutral or partisan, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4776, 509)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We've done a lot of the preprocessing of text for you! We have:\n",
    "- gotten rid of some of the excess columns,\n",
    "- broken each message (`text_feature`) out into columns and rows:\n",
    "    - each row corresponds to one tweet or Facebook post.\n",
    "    - each column corresponds to a word used.\n",
    "    - each value corresponds to how many times that word was used in that Facebook post.\n",
    "        - For example, if the word \"health\" was used four times in someone's Facebook post, then the value in the cell for that post and the \"health\" column should be 4.\n",
    "- and removed particularly common words.\n",
    "\n",
    "Over the next few days, you'll be learning how to do this on your own! If you want to check out the code that made this preprocessing happen, check out the `extras` folder in this repository. (This code will make more sense later this week.) \n",
    "\n",
    "You may note that there are some extra symbols in the data. This is a common problem in natural language processing, especially when dealing with social media (think emoji, hashtags, links, etc.), but we're going to ignore that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use Naive Bayes to predict whether a social media post was featured on Facebook or Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Engineer a feature to turn `source_feature` into a 1/0 column, where 1 indicates `Twitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitter'] = [1 if df.loc[i,'source_feature'] == 'twitter' else 0 for i in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Since we are solving a classification problem, what potential issue should I check for here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2391\n",
       "0    2385\n",
       "Name: twitter, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['twitter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split our data into `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Unnamed: 0', 'unit_id', 'trusted_judgments', 'audience_feature',\n",
    "                       'bias_feature', 'message_feature', 'label_feature', 'source_feature',\n",
    "                       'text_feature', 'twitter'])\n",
    "y = df['twitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>20</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>û_</th>\n",
       "      <th>ûª</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªre</th>\n",
       "      <th>ûªs</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûò</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   10  100   11   12   20  2013  2014   30 ...   young  youtube  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0 ...     0.0      0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0 ...     0.0      0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0 ...     0.0      0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  1.0 ...     0.0      0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0 ...     0.0      0.0   \n",
       "\n",
       "    û_   ûª  ûªm  ûªre  ûªs  ûªt  ûªve   ûò  \n",
       "0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  \n",
       "1  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  \n",
       "2  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  \n",
       "3  0.0  0.0  0.0   0.0  1.0  0.0   0.0  0.0  \n",
       "4  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Split our data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: This is where we would usually turn our words into features - after the train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit a Naive Bayes model!\n",
    "\n",
    "<details><summary> Which Naive Bayes model should we pick, and why? </summary>\n",
    "```\n",
    "- The columns of X are all integer counts, so MultinomialNB is the best choice here.\n",
    "- BernoulliNB is best when we have 0/1 counts in all columns of X. (a.k.a. dummy variables)\n",
    "- GaussianNB is best when the columns of X are Normally distributed. (Practically, though, it gets used whenever BernoulliNB and MultinomialNB are inappropriate.)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate our model!\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember earlier that I said we had the opportunity to set priors. We could do so here if we wanted, but we'll stick with the default and allow `sklearn` to estimate priors from the training data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our model!\n",
    "\n",
    "model = nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate our predictions!\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> How might we evaluate our model's performance? </summary>\n",
    "```\n",
    "- Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "- Sensitivity = TP / (TP + FN)\n",
    "- Specificity = TN / (TN + FP)\n",
    "- Precision = TP / (TP + FP)\n",
    "- AUC ROC\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> If we have to select only one, which one should we choose? </summary>\n",
    "```\n",
    "- It depends on how exactly you define \"positive\" and \"negative.\" In this case, it probably doesn't really matter - incorrectly mistaking a tweet for a Facebook post doesn't seem much better or worse than incorrectly mistaking a Facebook post for a tweet. \n",
    "- Because I believe false positives and false negatives are equally as bad, I'd probably use accuracy.\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8259048758600059"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8025122121423587"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[592, 108],\n",
       "       [175, 558]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 592\n",
      "False Positives: 108\n",
      "False Negatives: 175\n",
      "True Positives: 558\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> By default, what does a false positive mean here? </summary>\n",
    "```\n",
    "- False positives are things we falsely predict to be positive.\n",
    "- In this case, since Twitter = 1, a false positive means I incorrectly think something is a tweet when it's really a Facebook post.\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> How might you try to improve our model's performance? </summary>\n",
    "```\n",
    "- Try a non-default prior, if I think it's warranted.\n",
    "- Check out how a logistic regression model or k-NN model compares.\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
