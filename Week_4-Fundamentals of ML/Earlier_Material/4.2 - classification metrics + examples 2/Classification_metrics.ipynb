{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraudulent Transactions\n",
    "\n",
    "Let's consider the following scenario:  Prediction of fraudulent transactions.\n",
    "\n",
    "- Fraudulent tranactions = Positive / Success\n",
    "- Legitimate transactions = Negative / Fail\n",
    "\n",
    "**Model Performance**\n",
    "\n",
    "Correct Predictions\n",
    "- Fraudulent: **50**\n",
    "- Legitimate: **900**\n",
    "\n",
    "Incorrect Predictions\n",
    "- Fraudulent: **40**\n",
    "- Legitimate: **10**\n",
    "\n",
    "<img src=\"https://snag.gy/fxND5e.jpg\" style=\"width: 500px;\">\n",
    "\n",
    "### Classification Metrics\n",
    "#### Accuracy\n",
    "$$\n",
    "\\frac{\\text{# correct}}{\\text{TP + FP + FN + TN}} = \\frac{TP+TN}{1000} = \\frac{950}{1000} = .95\n",
    "$$\n",
    "\n",
    "#### Misclassification (Error) Rate\n",
    "$$\n",
    "1 - \\text{Accuracy} = 1- \\frac{950}{1000} = .05\n",
    "$$\n",
    "\n",
    "#### Sensitivity\n",
    "> P = Total Positive observations\n",
    "\n",
    "$$\n",
    "\\frac{TP}{P} = \\frac{50}{TP + FN} = \\frac{50}{50 + 10} = .83\n",
    "$$\n",
    "\n",
    "#### Specificity \n",
    "> N = Total Negative observations\n",
    "\n",
    "$$\n",
    "\\frac{TN}{N} = \\frac{900}{TN + FP} = \\frac{900}{900 + 40} = .96\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity / Specificity Trade-Off\n",
    "\n",
    "<img src=\"https://snag.gy/CE3ItG.jpg\" style=\"width: 700px;\">\n",
    "\n",
    "The decision threashold for prediction is .5\n",
    "- p > .5 = positive label\n",
    "- p < .5 = negative label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./titanic_clean.csv\")\n",
    "\n",
    "X = pd.get_dummies(df[[\"Pclass\", \"Age\", \"Sex\", \"Age\", \"SibSp\", \"Parch\"]]).copy()\n",
    "y = df['Survived']\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "model    = logistic.fit(X, y)\n",
    "\n",
    "### We will run a prediction and attach them back to our dataframe\n",
    "preds = model.predict(X)\n",
    "df['prediction'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch     Fare Embarked  prediction  \n",
       "0      0   7.2500        S           0  \n",
       "1      0  71.2833        C           1  \n",
       "2      0   7.9250        S           1  \n",
       "3      0  53.1000        S           1  \n",
       "4      0   8.0500        S           0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we change the threashold for prediction?\n",
    "\n",
    "- To .65 instead of .5?\n",
    "- To .45 instead of .5?\n",
    "\n",
    "Let's write a function to adjust our predicted labels based on these new threasholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC and ROC\n",
    "\n",
    "We can use the idea of **sensitivity** and **specificity** in a combined metric we typically plot that represents both of these stats combined into one curved line, called The **Reciever Operator Characteristic**.\n",
    "\n",
    "<img src=\"https://snag.gy/Oq23IS.jpg\" style=\"width: 400px;\">\n",
    "\n",
    "We generate the ROC by plotting the sensitivity and specificity as we move our “classification threshold” from 0 to 1.  The ROC gives us a sense about the tradeoff between sensitivity and specificity.  Also, the closer the curve is the upper left, the better overall accuracy of our model is.  \n",
    "\n",
    "The area under the curve is also refered to as **AUC**.  The acronym **AUC-ROC** refers to the “Area Under the Receiver Operating Characteristic curve.”\n",
    "\n",
    "#### Sensitivity\n",
    "> P = Total Positive observations\n",
    "\n",
    "$$\n",
    "\\frac{TP}{P} = \\frac{TP}{TP + FN} \n",
    "$$\n",
    "\n",
    "#### Specificity \n",
    "> N = Total Negative observations\n",
    "\n",
    "$$\n",
    "\\frac{TN}{N} = \\frac{TN}{TN + FP} \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate False positive rate and True positive rate\n",
    "\n",
    "# Plot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate one ROC curve per class. The ROC curve is generated by varying our threshold from 0 to 1. This doesn't actually change the threashold or our original perdictions but it does tell what our tradeoff between _sensitivity_ and _specificity_.\n",
    "\n",
    "- Identify optimal threshold for our classfier.\n",
    "- Also evaluate performance of our classifier.\n",
    "- Potentially identify class balance problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced / Unbalanced Classes\n",
    "\n",
    "In classification problems, methods generally work well when we have roughly equally-sized classes. (i.e. 50% in the positive class and 50% in the negative class for binary classification problems).\n",
    "\n",
    "When we have a balanced class problem, usually we're talking about the case when we have a disproportionate balance of classes in a dataset.  An example would be a data where fraudulent transactions are very rare (ie: %2 fraudulent, %98 legit -- this is an extreme example).\n",
    "\n",
    "- If $y = 1$ is a rare event (fraud), logistic regression will underestimate $y = 1$ and thus overestimate $y = 0$ (legit).\n",
    "\n",
    "#### Methods for Dealing with Unbalanced Classes\n",
    "\n",
    "- **Bias correction.**\n",
    "Gary King wrote a [great whitepaper](https://gking.harvard.edu/files/gking/files/0s.pdf) on this topic.  This is a rigous approach and while provide good results, as data scientists we prefer \"easier\" methods.\n",
    "\n",
    "\n",
    "- **Weighting observations.**\n",
    "Some models allow the weighting of classes such as Naive Bayes, Random Forests, SVMs, etc.\n",
    "\n",
    "\n",
    "- **Stratified cross-validation.**\n",
    "If we use $k$-fold cross-validation entirely randomly, we may run into issues where some of our folds have no observations from the minority class.\n",
    "\n",
    "<img src=\"https://snag.gy/PqISr3.jpg\">\n",
    "\n",
    "By stratifying on our output variable with unbalanced classes during cross- validation, we protect ourselves from this situation and ensure that our estimate of our model performance has lower variance.\n",
    "\n",
    "\n",
    "- **Changing threshold for classification.**\n",
    "\n",
    "By adjusting our classification threshold, we might find a better fit for our particular use-case.  We performed this operation earlier by manually changing our predicted labels by choosing a new threashold from the predicted probability.\n",
    "\n",
    "\n",
    "- **Purposefully optimizing evaluation metrics.**\n",
    "\n",
    "We might also consider optimizating our model for a specific metric such as precision, recall by class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling/undersampling.\n",
    "\n",
    "- **Oversampling** : you duplicate the observations of the minority class to obtain a more balanced dataset.\n",
    "\n",
    "- **Undersampling** : you drop observations of the majority class to obtain a balanced dataset, see below.\n",
    "\n",
    "<img src=\"https://snag.gy/7QZSmJ.jpg\" style=\"width: 500px\">\n",
    "\n",
    "**Recommendations**\n",
    "- Unecessary if balance is worse than 25/75\n",
    "- Target balance to 33/66 ratio.\n",
    "- Model assumptions should also be considered to choose over or under sampling.\n",
    "  - Number of variables may impact chosen model\n",
    "- If your minority class contains enough observations for proper analysis, undersampling is prefered.\n",
    "- **We should always evaluate on the real data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last piece of advice\n",
    "\n",
    "\n",
    "#### Use one at a time\n",
    "- Bias correction.\n",
    "- Oversampling/undersampling.\n",
    "- Weighting observations. (i.e. weighted least squares) ‣Stratified cross-validation.\n",
    "\n",
    "#### Use what you are comfortable defending\n",
    "- Changing threshold for classification.\n",
    "- Purposefully optimizing evaluation metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
